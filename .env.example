# Server Configuration
PORT=3000
NODE_ENV=development

# Memory Management
# Maximum memory usage in MB (recommended: 500 for low-spec VPS, 1000 for high-spec)
MAX_MEMORY_MB=500

# Maximum concurrent AI processing requests (recommended: 1-2 for low-spec, 4 for high-spec)
MAX_CONCURRENT=2

# Logging
# Log level: debug, info, warn, error
LOG_LEVEL=info

# File Upload
# Maximum file size in MB
MAX_FILE_SIZE_MB=10

# Maximum total upload size in MB
MAX_UPLOAD_SIZE_MB=50

# AI API Configuration
# Note: Users should configure these in the web UI for better security
# These environment variables are optional and only for advanced use cases

# AI_API_ENDPOINT=https://api.openai.com/v1/chat/completions
# AI_API_KEY=your-api-key-here
# AI_MODEL=gpt-4o

# For Azure OpenAI:
# AI_API_ENDPOINT=https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions?api-version=2024-02-15-preview
# AI_API_KEY=your-azure-api-key
# AI_MODEL=your-deployment-name

# For local models (LM Studio):
# AI_API_ENDPOINT=http://localhost:1234/v1/chat/completions
# AI_API_KEY=not-needed
# AI_MODEL=llava-v1.5-7b
